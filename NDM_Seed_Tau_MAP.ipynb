{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.12.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIsa0R69uJzC",
        "outputId": "c2d894aa-38c3-433c-9ae4-1227dfcf8f6d"
      },
      "id": "mIsa0R69uJzC",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.68.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.12.1)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "P1x9cmKjhXHh"
      },
      "id": "P1x9cmKjhXHh",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name_Seed = \"Seed\"\n",
        "\n",
        "# Check if the folder already exists, if not, create it\n",
        "if not os.path.exists(folder_name_Seed):\n",
        "    os.makedirs(folder_name_Seed)\n",
        "\n",
        "folder_name_Tau = \"Tau\"\n",
        "\n",
        "# Check if the folder already exists, if not, create it\n",
        "if not os.path.exists(folder_name_Tau):\n",
        "    os.makedirs(folder_name_Tau)\n",
        "\n",
        "folder_name_MAP = \"MAP\"\n",
        "\n",
        "# Check if the folder already exists, if not, create it\n",
        "if not os.path.exists(folder_name_MAP):\n",
        "    os.makedirs(folder_name_MAP)\n",
        "\n",
        "folder_name_MAP = \"Data\"\n",
        "\n",
        "# Check if the folder already exists, if not, create it\n",
        "if not os.path.exists(folder_name_MAP):\n",
        "    os.makedirs(folder_name_MAP)\n",
        "\n",
        "folder_name_MAP = \"labelData\"\n",
        "\n",
        "# Check if the folder already exists, if not, create it\n",
        "if not os.path.exists(folder_name_MAP):\n",
        "    os.makedirs(folder_name_MAP)"
      ],
      "metadata": {
        "id": "BcNjyjqonoKx"
      },
      "id": "BcNjyjqonoKx",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEWSiKEpk_XQ",
        "outputId": "37b44260-8bdd-485d-b33a-1bab20393b3d"
      },
      "id": "OEWSiKEpk_XQ",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import networkx as nx\n",
        "import random\n",
        "import copy\n",
        "import pandas as pd\n",
        "import ast\n",
        "from ast import literal_eval\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "\n",
        "import time\n",
        "from operator import itemgetter\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "def get_wic_list(pathDataset):\n",
        "    wic = pd.read_csv(pathDataset)\n",
        "    return dict(zip(np.array(wic['Node'],dtype=str),wic['WIC']))\n",
        "\n",
        "\n",
        "def nodesRank(rank):\n",
        "    rWIC = sorted(rank)\n",
        "    re = []\n",
        "    for i in rWIC:\n",
        "        re.append(rank.index(i))\n",
        "    return re\n",
        "\n",
        "\n",
        "def compare_tau1(wic,alg_list):\n",
        "    wic_sort = [i for i,j in sorted(wic.items(),key=lambda x:x[1],reverse=True)]\n",
        "    wic_sort=[int(i) for i in wic_sort]\n",
        "    alg_list=[int(i) for i in alg_list]\n",
        "    tau,_ = stats.kendalltau(nodesRank(alg_list),nodesRank(wic_sort))\n",
        "    return tau\n",
        "\n",
        "def rel_at_k(y_true, y_pred, k):\n",
        "    \"\"\" Computes Relevance at k for one sample\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "    y_true: np.array\n",
        "            Array of correct recommendations (Order doesn't matter)\n",
        "    y_pred: np.array\n",
        "            Array of predicted recommendations (Order does matter)\n",
        "    k: int, optional\n",
        "       Maximum number of predicted recommendations\n",
        "\n",
        "    Returns\n",
        "    _______a\n",
        "    score: double\n",
        "           Relevance at k\n",
        "    \"\"\"\n",
        "    # if y_pred[k] ==  y_true[k]:\n",
        "    if y_pred[k-1] in  y_true:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def precision_at_k(y_true, y_pred, k):\n",
        "    \"\"\" Computes Precision at k for one sample\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "    y_true: np.array\n",
        "            Array of correct recommendations (Order doesn't matter)\n",
        "    y_pred: np.array\n",
        "            Array of predicted recommendations (Order does matter)\n",
        "    k: int, optional\n",
        "       Maximum number of predicted recommendations\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "    score: double\n",
        "           Precision at k\n",
        "    \"\"\"\n",
        "    intersection = np.intersect1d(y_true, y_pred[:k])\n",
        "    return len(intersection) / k\n",
        "\n",
        "\n",
        "def average_precision_at_k(y_true, y_pred, k):\n",
        "    \"\"\" Computes Average Precision at k for one sample\n",
        "\n",
        "    Parameters\n",
        "    __________\n",
        "    y_true: np.array\n",
        "            Array of correct recommendations (Order doesn't matter)\n",
        "    y_pred: np.array\n",
        "            Array of predicted recommendations (Order does matter)\n",
        "    k: int, optional\n",
        "       Maximum number of predicted recommendations\n",
        "\n",
        "    Returns\n",
        "    _______\n",
        "    score: double\n",
        "           Average Precision at k\n",
        "    \"\"\"\n",
        "    ap = 0.0\n",
        "    for i in range(1, k+1):\n",
        "        ap += precision_at_k(y_true, y_pred, i) * rel_at_k(y_true, y_pred, i)\n",
        "\n",
        "    return ap / min(k, len(y_true))\n",
        "\n",
        "\n",
        "\n",
        "def compare_MAP(wicc,alg_list,per):\n",
        "    wic_sort = [i for i,j in sorted(wicc.items(),key=lambda x:x[1],reverse=True)]\n",
        "    k=int(per*len(wic_sort)/100)\n",
        "    map=average_precision_at_k(wic_sort[:k],alg_list[:k],k)\n",
        "    return map\n",
        "\n",
        "def get_algo_list(df_M,dataName,algoName):\n",
        "    algo_list=[]\n",
        "    df = df_M.copy()\n",
        "    df=df[df['Dataset']==dataName]\n",
        "    df=df[df['Algo']==algoName]\n",
        "    #algo_list=literal_eval(df['Seed'].iloc[0])\n",
        "    algo_list=df['Seed'].iloc[0]\n",
        "    return algo_list\n"
      ],
      "metadata": {
        "id": "I3MHTdSn6sGC"
      },
      "id": "I3MHTdSn6sGC",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "88bdcd06-6a2b-453e-9ba6-684794526c68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88bdcd06-6a2b-453e-9ba6-684794526c68",
        "outputId": "8949b9e1-6d1e-454a-d9ff-efc6c2b0c032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file =  Email\n",
            "NDM Centrality is selected\n",
            "(1133, 4, 11)\n",
            "36/36 [==============================] - 1s 3ms/step\n",
            "1133\n",
            " NDM has tau= 0.9582084524964212 in Email\n",
            "Yes,it is equal,   -file = Email\n",
            "-------------------------------------------------------------\n",
            "done NDM  in   Email\n",
            "-------------------------------------------------------------\n",
            "Email  MAP= 0.9409366067686004\n",
            "Email  MAP= 0.9638774180776223\n",
            "Email  MAP= 0.9692143718617781\n",
            "Email  MAP= 0.9816752525381208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-3bfbc7e86cf8>:94: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_Seed_result=df_Seed_result._append(df2, ignore_index = True)\n",
            "<ipython-input-55-3bfbc7e86cf8>:98: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_tau_result=df_tau_result._append(df2, ignore_index = True)\n",
            "<ipython-input-55-3bfbc7e86cf8>:112: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_map_result=df_map_result._append(df2, ignore_index = True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file =  PGP\n",
            "NDM Centrality is selected\n",
            "(10680, 4, 11)\n",
            "334/334 [==============================] - 1s 2ms/step\n",
            "10680\n",
            " NDM has tau= 0.9212111838383499 in PGP\n",
            "Yes,it is equal,   -file = PGP\n",
            "-------------------------------------------------------------\n",
            "done NDM  in   PGP\n",
            "-------------------------------------------------------------\n",
            "PGP  MAP= 0.9669860733272465\n",
            "PGP  MAP= 0.9610513969561415\n",
            "PGP  MAP= 0.9687952856379402\n",
            "PGP  MAP= 0.9778586988892313\n"
          ]
        }
      ],
      "source": [
        "import Base__NDM\n",
        "\n",
        "def NDM_(G):\n",
        "    start_time = time.time()\n",
        "    seedB=Base__NDM.NDM_rank(G)\n",
        "    seedB=[i for i in seedB]\n",
        "    timelapse=(time.time() - start_time)\n",
        "    return seedB,timelapse\n",
        "\n",
        "\n",
        "def seedAlgo(Algo,G,k  ):\n",
        "    if Algo=='NDM':\n",
        "        print('NDM Centrality is selected')\n",
        "        return NDM_(G)\n",
        "\n",
        "\n",
        "def loadData(nameDataset,sep=\",\"):\n",
        "    df = pd.read_csv(nameDataset, sep=sep, names=['FromNodeId', 'ToNodeId'], skiprows=1)\n",
        "    df['FromNodeId'] = df['FromNodeId'].astype(int)\n",
        "    df['ToNodeId'] = df['ToNodeId'].astype(int)\n",
        "\n",
        "    G = nx.from_pandas_edgelist(df, source=\"FromNodeId\", target=\"ToNodeId\")\n",
        "    G.remove_edges_from(nx.selfloop_edges(G))\n",
        "    G.remove_nodes_from(['FromNodeId', 'ToNodeId'])\n",
        "    return G\n",
        "\n",
        "\n",
        "def files(path):\n",
        "    filesList=[]\n",
        "    for file in os.listdir(path):\n",
        "        if os.path.isfile(os.path.join(path, file)):\n",
        "            filesList.append(file)\n",
        "    return filesList\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_Datasets_to_pred= [\n",
        " 'CiaoDVD',\n",
        " 'Email',\n",
        " 'Gnutella',\n",
        " 'GrQc',\n",
        " 'Hamster',\n",
        " 'Jazz',\n",
        " 'LastFM',\n",
        " 'NetScience',\n",
        " 'PGP',\n",
        " 'Politician',\n",
        " 'PowerGrid',\n",
        " 'Sex',\n",
        "]\n",
        "\n",
        "\n",
        "input_Datasets_to_pred= [\n",
        "  'Email',\n",
        "  'PGP',\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "Tau_='Tau_'\n",
        "seed_='seed_'\n",
        "MAP_='MAP_'\n",
        "pathDataset='/content/Data/'\n",
        "pathLabelDataset='/content/labelData/'\n",
        "\n",
        "Algorithms=[  'NDM', ]\n",
        "\n",
        "\n",
        "for Algo in Algorithms:\n",
        "    df_Seed_result = pd.DataFrame( columns=['Dataset','Algo','Seed','time'])\n",
        "    df_tau_result = pd.DataFrame( columns=['Dataset','Algo','Tau'])\n",
        "    df_map_result = pd.DataFrame( columns=['Dataset','Algo','MAP','NumK'])\n",
        "\n",
        "    for file in input_Datasets_to_pred:\n",
        "\n",
        "      G =loadData(pathDataset+file+'.csv')\n",
        "      print('file = ', file)\n",
        "      k=G.number_of_nodes()\n",
        "\n",
        "      Seed,timeS=seedAlgo(Algo,G,k )\n",
        "      Seed=[str(i) for i in Seed]\n",
        "\n",
        "      print(len(Seed))\n",
        "\n",
        "      path_WIC_data=pathLabelDataset+file+'_OneNodeIM.csv'\n",
        "      G_WIC = get_wic_list(path_WIC_data)\n",
        "      tau=compare_tau1(G_WIC,Seed)\n",
        "      print(f' {Algo} has tau= {tau} in {file}')\n",
        "\n",
        "      if G.number_of_nodes()==len(Seed):\n",
        "          print('Yes,it is equal,  ','-file =', file)\n",
        "          df2 = {'Dataset': file, 'Algo': Algo, 'Seed': Seed,'time':timeS}\n",
        "          df_Seed_result=df_Seed_result._append(df2, ignore_index = True)\n",
        "          df_Seed_result.to_csv(f'/content/Seed/{seed_}'+Algo+'.csv')\n",
        "\n",
        "          df2= {'Dataset': file,'Algo': Algo, 'Tau': tau}\n",
        "          df_tau_result=df_tau_result._append(df2, ignore_index = True)\n",
        "          df_tau_result.to_csv(f'/content/Tau/{Tau_}'+Algo+'.csv')\n",
        "\n",
        "          print('-------------------------------------------------------------')\n",
        "          print('done', Algo,' in  ', file)\n",
        "          print('-------------------------------------------------------------')\n",
        "\n",
        "          for per in [5,10,15,20]:\n",
        "            G_WIC=get_wic_list(path_WIC_data)\n",
        "\n",
        "            MAP=compare_MAP(G_WIC,Seed,per)\n",
        "            print(file,' MAP=',MAP)\n",
        "\n",
        "            df2 = {'Dataset': file, 'Algo': Algo, 'MAP': MAP,'numK':per}\n",
        "            df_map_result=df_map_result._append(df2, ignore_index = True)\n",
        "            df_map_result.to_csv(f'/content/MAP/{MAP_}'+Algo+'.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wSF0rTtxoXKg"
      },
      "id": "wSF0rTtxoXKg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316add97-5f56-4fea-9a1c-21743e5158fc",
      "metadata": {
        "id": "316add97-5f56-4fea-9a1c-21743e5158fc"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# Zip the folder\n",
        "# Download the ZIP file\n",
        "from google.colab import files\n",
        "shutil.make_archive(folder_name_Tau, 'zip', folder_name_Tau)\n",
        "zip_file_path = folder_name_Tau + \".zip\"\n",
        "files.download(zip_file_path)\n",
        "\n",
        "\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(folder_name_MAP, 'zip', folder_name_MAP)\n",
        "zip_file_path = folder_name_MAP + \".zip\"\n",
        "files.download(zip_file_path)\n",
        "\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(folder_name_Seed, 'zip', folder_name_Seed)\n",
        "zip_file_path = folder_name_Seed + \".zip\"\n",
        "files.download(zip_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KkJBlcX3oT7D"
      },
      "id": "KkJBlcX3oT7D",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}